{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwUAZDJ6yyAw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ],
      "metadata": {
        "id": "QVHCg-05zx73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jjua6mnsqcaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "tSn6INJOz3sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n"
      ],
      "metadata": {
        "id": "2VYirdfp0HiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "# Define the device for training\n",
        "device = torch.device('cuda' if cuda_available else 'cpu')\n"
      ],
      "metadata": {
        "id": "gS7DiLlr0LL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if cuda_available:\n",
        "    print(\"CUDA is available! Training on GPU.\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Training on CPU.\")\n",
        "\n",
        "# Optionally, to identify the GPU\n",
        "if cuda_available:\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "id": "Kq2fhZ_V0r3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n"
      ],
      "metadata": {
        "id": "eNzVO7dt0vbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5-r-2Zoecqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        real_images = Variable(images.view(images.size(0), -1)).to(device)\n",
        "        fake_labels = Variable(torch.zeros(images.size(0))).to(device)\n",
        "        real_labels = Variable(torch.ones(images.size(0))).to(device)\n",
        "\n",
        "        # Train the discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        outputs = discriminator(real_images).squeeze()\n",
        "        real_loss = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "\n",
        "        z = Variable(torch.randn(images.size(0), 100)).to(device)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images).squeeze()\n",
        "        fake_loss = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train the generator\n",
        "        optimizer_g.zero_grad()\n",
        "        z = Variable(torch.randn(images.size(0), 100)).to(device)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images).squeeze()\n",
        "\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, D(x): %.2f, D(G(z)): %.2f'\n",
        "                  %(epoch, num_epochs, i+1, len(train_loader), d_loss.data, g_loss.data, real_score.data.mean(), fake_score.data.mean()))\n"
      ],
      "metadata": {
        "id": "eXEiCJGj0_Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained models\n",
        "torch.save(generator.state_dict(), 'generator_gpu.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator_gpu.pth')\n"
      ],
      "metadata": {
        "id": "gf28Iz5lefGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "# Define the device for training\n",
        "device = torch.device('cuda' if cuda_available else 'cpu')\n",
        "\n",
        "# Create the models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Load the models from disk\n",
        "generator.load_state_dict(torch.load('generator_gpu.pth', map_location=device))\n",
        "discriminator.load_state_dict(torch.load('discriminator_gpu.pth', map_location=device))\n",
        "\n",
        "# Set the models to evaluation mode\n",
        "generator.eval()\n",
        "discriminator.eval()\n"
      ],
      "metadata": {
        "id": "_Jh5tyAieqjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate fake images\n",
        "z = Variable(torch.randn(64, 100)).to(device)\n",
        "fake_images = generator(z)\n",
        "fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
        "fake_images = fake_images.data.cpu().numpy()  # move data back to CPU for numpy and plotting\n",
        "fake_images = fake_images * 0.5 + 0.5  # unnormalize\n",
        "\n",
        "# Plot the fake images\n",
        "fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(fake_images[i, 0], cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "okWugjm2e3DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path for the ONNX model\n",
        "onnx_path = Path('generator.onnx')\n",
        "\n",
        "# Load the trained generator model\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load('generator_gpu.pth'))\n",
        "generator.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Suppress warnings and export the model to ONNX format if it doesn't already exist\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    if not onnx_path.exists():\n",
        "        # Assume IMAGE_HEIGHT and IMAGE_WIDTH are both 32 for CIFAR-10 dataset\n",
        "        IMAGE_HEIGHT, IMAGE_WIDTH = 32, 32\n",
        "        dummy_input = torch.randn(1, 100, 1, 1).to(device)  # Adjust the input dimensions to match your model\n",
        "        torch.onnx.export(\n",
        "            generator,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "        )\n",
        "        print(f\"ONNX model exported to {onnx_path}.\")\n",
        "    else:\n",
        "        print(f\"ONNX model {onnx_path} already exists.\")\n"
      ],
      "metadata": {
        "id": "nIWeISfEpRuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path for the ONNX model\n",
        "onnx_path = Path('generator.onnx')\n",
        "\n",
        "# Load the trained generator model\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load('generator_gpu.pth'))\n",
        "generator.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Suppress warnings and export the model to ONNX format if it doesn't already exist\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    if not onnx_path.exists():\n",
        "        # Adjust the input dimensions to match your model\n",
        "        dummy_input = torch.randn(1, 100).to(device)  # Adjusted input dimensions\n",
        "        torch.onnx.export(\n",
        "            generator,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "        )\n",
        "        print(f\"ONNX model exported to {onnx_path}.\")\n",
        "    else:\n",
        "        print(f\"ONNX model {onnx_path} already exists.\")\n"
      ],
      "metadata": {
        "id": "obzkKlU5qf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOr0jDjYrr8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "id": "6k-l-Ms8rBLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "hajFaGrFqlZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install openvino package\n",
        "%pip install -q \"openvino>=2023.1.0\" onnx"
      ],
      "metadata": {
        "id": "qUBmTqLErut2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import openvino as ov\n",
        "import torch\n",
        "from torchvision.models.segmentation import lraspp_mobilenet_v3_large, LRASPP_MobileNet_V3_Large_Weights\n",
        "\n",
        "# Fetch `notebook_utils` module\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\n",
        "    url='https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py',\n",
        "    filename='notebook_utils.py'\n",
        ")\n",
        "\n",
        "from notebook_utils import segmentation_map_to_image, viz_result_image, SegmentationMap, Label, download_file\n",
        "\n",
        "# Define the path for the ONNX model\n",
        "onnx_path = Path('generator.onnx')\n",
        "\n",
        "# Load the trained generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load('generator_gpu.pth'))\n",
        "generator.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Suppress warnings and export the model to ONNX format if it doesn't already exist\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    if not onnx_path.exists():\n",
        "        # Adjust the input dimensions to match your model\n",
        "        dummy_input = torch.randn(1, 100).to(device)  # Adjusted input dimensions\n",
        "        torch.onnx.export(\n",
        "            generator,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "        )\n",
        "        print(f\"ONNX model exported to {onnx_path}.\")\n",
        "    else:\n",
        "        print(f\"ONNX model {onnx_path} already exists.\")\n"
      ],
      "metadata": {
        "id": "oXO8lVq5saoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.onnx\n",
        "\n",
        "# Define the model and input dimensions\n",
        "IMAGE_WIDTH = 780\n",
        "IMAGE_HEIGHT = 520\n",
        "DIRECTORY_NAME = \"model\"\n",
        "BASE_MODEL_NAME = DIRECTORY_NAME + \"/generator\"\n",
        "weights_path = Path(BASE_MODEL_NAME + \".pt\")\n",
        "\n",
        "# Paths where ONNX and OpenVINO IR models will be stored.\n",
        "onnx_path = weights_path.with_suffix('.onnx')\n",
        "if not onnx_path.parent.exists():\n",
        "    onnx_path.parent.mkdir()\n",
        "ir_path = onnx_path.with_suffix(\".xml\")\n",
        "\n",
        "# Load the trained generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load('generator_gpu.pth'))\n",
        "generator.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Suppress warnings and export the model to ONNX format if it doesn't already exist\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    if not onnx_path.exists():\n",
        "        # Adjust the input dimensions to match your model\n",
        "        dummy_input = torch.randn(1, 100).to(device)  # Adjusted input dimensions\n",
        "        torch.onnx.export(\n",
        "            generator,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "        )\n",
        "        print(f\"ONNX model exported to {onnx_path}.\")\n",
        "    else:\n",
        "        print(f\"ONNX model {onnx_path} already exists.\")\n"
      ],
      "metadata": {
        "id": "ss2cA9cIzHLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not ir_path.exists():\n",
        "    print(\"Exporting ONNX model to IR... This may take a few minutes.\")\n",
        "    ov_model = ov.convert_model(onnx_path)\n",
        "    ov.save_model(ov_model, ir_path)\n",
        "else:\n",
        "    print(f\"IR model {ir_path} already exists.\")"
      ],
      "metadata": {
        "id": "mdOz3lfv1IYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}